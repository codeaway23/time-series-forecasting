{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file):\n",
    "\treturn pd.read_csv(file)\n",
    "\n",
    "def drop_duplicates(df):\n",
    "\treturn df.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "\n",
    "def sort_by_date(df):\n",
    "\treturn df.sort_values(by=['Sale Date'], inplace=False, ascending=True)\n",
    "\n",
    "def process_datetime(df):\n",
    "\tdf['Sale Date'] = df['Sale Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "\treturn df\n",
    "\n",
    "def get_year_month_week(df):\n",
    "\tdf['Year'] = df['Sale Date'].apply(lambda x: x.year)\n",
    "\tdf['Month'] = df['Sale Date'].apply(lambda x: x.month)\n",
    "\tdf['Week'] = df['Sale Date'].apply(lambda x: x.isocalendar()[1])\n",
    "\treturn df\n",
    "\n",
    "def groupd_df_by_year_and_month(df):\n",
    "\treturn df.groupby(['Year','Month'])\n",
    "\n",
    "def get_unique_value_counts(df):\n",
    "\treturn df.nunique()\n",
    "\n",
    "def separate_sales_and_return(df):\n",
    "\treturn df[df['Sale/Return'] == 'Sale'], df[df['Sale/Return'] == 'Return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sales_quantity_anomalies(df):\n",
    "    df = df[df['Sales Qty'] != 0]\n",
    "    df = df[(df['Sale/Return']=='Sale') & (df['Sales Qty'] > 0)]\n",
    "    df = df[(df['Sale/Return']=='Return') & (df['Sales Qty'] < 0)]\n",
    "    return df\n",
    "\n",
    "def check_mrp_sales_price_find_anomalies(df):\n",
    "\tno_anomalies_df = df[df['MRP'] == df['Sales Price']]\n",
    "\tdiscounted_df = df[df['MRP'] > df['Sales Price']]\n",
    "\tneed_correction_df = df[df['MRP'] < df['Sales Price']]\n",
    "\treturn no_anomalies_df, discounted_df, need_correction_df\n",
    "\n",
    "def correct_mrp_sales_price_anomalies(need_correction_df):\n",
    "\tneed_correction_df['Sales Price'] = need_correction_df['MRP']\n",
    "\treturn need_correction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_discounts(discounted_df):\n",
    "\tdiscounted_df['Discount'] = (discounted_df['MRP'] - discounted_df['Sales Price'])*discounted_df['Sales Qty']\n",
    "\treturn discounted_df\n",
    "\n",
    "def calculate_sales(df):\n",
    "\tdf['Sales'] = df['Sales Price']*df['Sales Qty']\n",
    "\treturn df\n",
    "\n",
    "def get_sales_metrics_by_year_and_month(df):\n",
    "\treturn df.groupby(['Year','Month'])['Sales'].sum()\n",
    "\n",
    "def get_discount_metrics_by_year_and_month(df):\n",
    "    sales_df = get_sales_metrics_by_year_and_month(df)\n",
    "    discounts_df = df.groupby(['Year','Month'])['Discount'].sum()\n",
    "    return discounts_df/sales_df.values * 100    \n",
    "\n",
    "def get_average_selling_price_by_year_and_month(df):\n",
    "    return df.groupby(['Year','Month'])['Sales Price'].mean()\n",
    "\n",
    "def get_unique_SKU_by_year_and_month(df):\n",
    "    return df.groupby(['Year','Month'])['SKU Code'].nunique()\n",
    "\n",
    "def get_sales_metrics_by_category_year_and_month(df):\n",
    "\treturn df.groupby(['Category','Brand Code','Year','Month'])['Sales'].sum().reset_index()\n",
    "\n",
    "def get_discount_metrics_by_category_year_and_month(df):\n",
    "\treturn df.groupby(['Category','Brand Code','Year','Month'])['Discount'].sum().reset_index()\n",
    "\n",
    "def get_average_selling_price_by_category_year_and_month(df):\n",
    "    return df.groupby(['Category','Brand Code','Year','Month'])['Sales Price'].mean().reset_index()\n",
    "\n",
    "def get_unique_SKU_by_category_year_and_month(df):\n",
    "    return df.groupby(['Category','Brand Code','Year','Month'])['SKU Code'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files():\n",
    "\tthis_dir = os.getcwd()\n",
    "\tparent_dir = os.path.dirname(os.path.normpath(this_dir))\n",
    "\tdata_dir = os.path.join(parent_dir, 'data')\n",
    "\tfiles = [os.path.join(data_dir, x) for x in os.listdir(data_dir)]\n",
    "\tfiles.sort()\n",
    "\treturn files\n",
    "\n",
    "def merge_stores_data(files):\n",
    "\tfor i,file in enumerate(files):\n",
    "\t\tif i == 0:\n",
    "\t\t\tdf = read_csv(file)\n",
    "\t\telse:\n",
    "\t\t\tdf = df.append(read_csv(file))\n",
    "\treturn df\n",
    "\n",
    "def split_stores_into_dfs(df):\n",
    "\tstores = np.unique(df['Store Code'].values)\n",
    "\tstores.sort()\n",
    "\tstore_dfs = {}\n",
    "\tfor store in stores:\n",
    "\t\tstore_dfs[store] = df[df['Store Code'] == store]\n",
    "\treturn store_dfs\n",
    "\n",
    "def preprocess(df):\n",
    "    df = process_datetime(df)\n",
    "    df = get_year_month_week(df)\n",
    "    df = check_sales_quantity_anomalies(df)\n",
    "    no_anomalies_df, discounted_df, need_correction_df = check_mrp_sales_price_find_anomalies(df)\n",
    "    corrected_df = correct_mrp_sales_price_anomalies(need_correction_df)\n",
    "    no_anomalies_df['Discount'] = 0.\n",
    "    corrected_df['Discount'] = 0.\n",
    "    discounted_df = calculate_discounts(discounted_df)\n",
    "    preprocessed_df = no_anomalies_df.append(corrected_df)\n",
    "    preprocessed_df = preprocessed_df.append(discounted_df)\n",
    "    preprocessed_df = calculate_sales(preprocessed_df)\n",
    "    preprocessed_df = sort_by_date(preprocessed_df)\n",
    "    return preprocessed_df\n",
    "\n",
    "def get_preprocessed_store_dfs():\n",
    "    files = get_files()\n",
    "    df = merge_stores_data(files)\n",
    "    preprocessed_df = preprocess(df)\n",
    "    store_dfs = split_stores_into_dfs(preprocessed_df)\n",
    "    return store_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales_discount_selling_price_metrics_by_store_year_month(store_dfs):\n",
    "    sales_metrics = {}\n",
    "    discount_metrics = {}\n",
    "    selling_price_metrics = {}\n",
    "    sku_metrics = {}\n",
    "    for store in store_dfs:\n",
    "        sales_metrics[store] = get_sales_metrics_by_year_and_month(store_dfs[store])\n",
    "        discount_metrics[store] = get_discount_metrics_by_year_and_month(store_dfs[store])\n",
    "        selling_price_metrics[store] = get_average_selling_price_by_year_and_month(store_dfs[store])\n",
    "        sku_metrics[store] = get_unique_SKU_by_year_and_month(store_dfs[store])\n",
    "    return sales_metrics, discount_metrics, selling_price_metrics, sku_metrics\n",
    "\n",
    "def get_sales_discount_selling_price_metrics_by_store_category_year_month(store_dfs):\n",
    "    sales_metrics = {}\n",
    "    discount_metrics = {}\n",
    "    selling_price_metrics = {}\n",
    "    sku_metrics = {}\n",
    "    for store in store_dfs:\n",
    "        sales_metrics[store] = get_sales_metrics_by_category_year_and_month(store_dfs[store])\n",
    "        discount_metrics[store] = get_discount_metrics_by_category_year_and_month(store_dfs[store])\n",
    "        selling_price_metrics[store] = get_average_selling_price_by_category_year_and_month(store_dfs[store])\n",
    "        sku_metrics[store] = get_unique_SKU_by_category_year_and_month(store_dfs[store])\n",
    "    return sales_metrics, discount_metrics, selling_price_metrics, sku_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dfs = get_preprocessed_store_dfs()\n",
    "sales_metrics, discount_metrics, selling_price_metrics, sku_metrics = get_sales_discount_selling_price_metrics_by_store_year_month(store_dfs)\n",
    "deep_dive_sales_metrics, deep_dive_discount_metrics, deep_dive_selling_price, deep_dive_sku_metrics = get_sales_discount_selling_price_metrics_by_store_category_year_month(store_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(os.path.normpath(this_dir))\n",
    "preproc_dir = os.path.join(parent_dir, 'preproc_files')\n",
    "if not os.path.exists(preproc_dir):\n",
    "    os.makedirs(preproc_dir)\n",
    "f_store_dfs = os.path.join(preproc_dir, 'store_dfs')\n",
    "f_sales_metrics = os.path.join(preproc_dir, 'sales_metrics')\n",
    "f_discount_metrics = os.path.join(preproc_dir, 'disc_metrics')\n",
    "f_selling_price_metrics = os.path.join(preproc_dir, 'sale_price_metrics')\n",
    "f_sku_metrics = os.path.join(preproc_dir, 'sku_metrics')\n",
    "f_sales_metrics_deep = os.path.join(preproc_dir, 'sales_metrics_deep')\n",
    "f_discount_metrics_deep = os.path.join(preproc_dir, 'disc_metrics_deep')\n",
    "f_selling_price_metrics_deep = os.path.join(preproc_dir, 'sale_price_metrics_deep')\n",
    "f_sku_metrics_deep = os.path.join(preproc_dir, 'sku_metrics_deep')\n",
    "files = [f_store_dfs,\n",
    "         f_sales_metrics,\n",
    "         f_discount_metrics,\n",
    "         f_selling_price_metrics,\n",
    "         f_sku_metrics,\n",
    "         f_sales_metrics_deep,\n",
    "         f_discount_metrics_deep,\n",
    "         f_selling_price_metrics_deep,\n",
    "         f_sku_metrics_deep]\n",
    "data = [store_dfs,\n",
    "        sales_metrics,\n",
    "        discount_metrics,\n",
    "        selling_price_metrics,\n",
    "        sku_metrics,\n",
    "        deep_dive_sales_metrics,\n",
    "        deep_dive_discount_metrics,\n",
    "        deep_dive_selling_price,\n",
    "        deep_dive_sku_metrics]\n",
    "for i,file in enumerate(files):\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(data[i], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
